{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hskimim/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/hskimim/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/hskimim/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn의 교차 검증 기능\n",
    "- data를 train set과 test set으로 단순 분리\n",
    "    - data splitter\n",
    "        - `train_test_split()`\n",
    "- 복수의 test set 준비\n",
    "    - cross validation generator\n",
    "        - `KFold`\n",
    "        - `LeaveOneOut`\n",
    "        - `ShuffleSplit`\n",
    "- 복수의 test set 사용하여 평가 과정 반복\n",
    "    - cross validation calculator\n",
    "        - `cross_val_score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(10).reshape(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5],\n",
       "       [0, 1],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [8, 9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "- KFold 클래스를 비롯한 교차 검증 클래스 객체들은 Cross Validation Generator 들로서 트레이닝/테스트용 데이터 인덱스를 내보내는 split method를 제공한다.\n",
    "####  K-fold CV\n",
    "- K-fold CV 방법은 데이터 셋을 K개의 Sub-set으로 분리하는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[  0  10]\n",
      " [ 20  30]\n",
      " [ 40  50]\n",
      " [ 60  70]\n",
      " [ 80  90]\n",
      " [100 110]\n",
      " [120 130]\n",
      " [140 150]\n",
      " [160 170]\n",
      " [180 190]\n",
      " [200 210]\n",
      " [220 230]\n",
      " [240 250]\n",
      " [260 270]\n",
      " [280 290]\n",
      " [300 310]\n",
      " [320 330]\n",
      " [340 350]\n",
      " [360 370]\n",
      " [380 390]]\n",
      "y:\n",
      "[1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "X = np.arange(8 * N).reshape(-1, 2) * 10\n",
    "y = np.hstack([np.ones(N), np.ones(N) * 2, np.ones(N) * 3, np.ones(N) * 4])\n",
    "print(\"X:\\n\", X, sep=\"\")\n",
    "print(\"y:\\n\", y, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test index : [ 1  6  8 10 17 18 19]\n",
      "................................................................................\n",
      "train index: [ 0  2  3  4  5  7  9 11 12 13 14 15 16]\n",
      "================================================================================\n",
      "test index : [ 2  4  5  7  9 13 14]\n",
      "................................................................................\n",
      "train index: [ 0  1  3  6  8 10 11 12 15 16 17 18 19]\n",
      "================================================================================\n",
      "test index : [ 0  3 11 12 15 16]\n",
      "................................................................................\n",
      "train index: [ 1  2  4  5  6  7  8  9 10 13 14 17 18 19]\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "for train_index, test_index in cv.split(X):\n",
    "    print(\"test index :\", test_index)\n",
    "    print(\".\" * 80 )        \n",
    "    print(\"train index:\", train_index)\n",
    "    print(\"=\" * 80 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-fold method Parameter instruction\n",
    "- n_splits : int, default=3\n",
    "    Number of folds. Must be at least 2.\n",
    "- shuffle : boolean, optional\n",
    "    Whether to shuffle the data before splitting into batches.\n",
    "- random_state : int, RandomState instance or None, optional, default=None\n",
    "    If int, random_state is the seed used by the random number generator;\n",
    "    If RandomState instance, random_state is the random number generator;\n",
    "    If None, the random number generator is the RandomState instance used\n",
    "    by `np.random`. Used when ``shuffle`` == True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 평가 시행\n",
    "- Cross Validation 은 단순히 데이터 셋을 나누느 역할을 수행할 뿐이다. 실제로 묘형의 성능을 구하려면 이렇게 나누어진 데이터셋을 사용하여 평가를 반복하여야 한다. 이 과정을 자동화하는 명령이 바로바로바로 `cross_val_score()`이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without cross_val_score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95636425, 0.94908323, 0.93880683, 0.92906829, 0.93119768,\n",
       "       0.95362566, 0.93217768, 0.94308775, 0.94579305, 0.94749884])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X,y,coef = make_regression(n_samples=1000, n_features=1, noise=20,coef=True,random_state=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "cv = KFold(10)\n",
    "\n",
    "scores = np.zeros(10)\n",
    "for i ,(train_index,test_index) in enumerate(cv.split(X)):\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    scores[i] = r2_score(y_test, y_pred)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with cross_val_score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95636425, 0.94908323, 0.93880683, 0.92906829, 0.93119768,\n",
       "       0.95362566, 0.93217768, 0.94308775, 0.94579305, 0.94749884])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model,X,y,scoring='r2',cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practicing CV from scik-learn.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation iterators for i.i.d. data\n",
    "- Assuming that some data is independent and identically Distributed(i.i.d.) is making the assumption that all samples stem from the `same generative process` and that the generative process is assumed to have no memory of `past generated` samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold\n",
    "- KFold divides all the samples in k groups of samples, called folds(if k=n, this is equivalent to the Leave One Out strategy),of equal sizes. The prediction function is learned using k-1 folds, and the fold left out is used for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3],[0 1]\n",
      "[0 1],[2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = ['a','b','c','d']\n",
    "kf = KFold(n_splits=2)\n",
    "for train,test in kf.split(X):\n",
    "    print('%s,%s'%(train,test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing cross-validated metrics\n",
    "- The simplest way to use cross-validation is to call the `cross_val_score` helper function on the estimator and the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
