{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA(Latent Dirichlet Allocation)\n",
    "- 주어진 문서에 대하여 각 문서에 어떤 주제들이 존재하는지에 대한 확률모형\n",
    "- 토픽별 단어의 분포, 문서별 토픽의 분포를 모두 추정\n",
    "- 특정 토픽에 특정 단어가 나타날 확률을 준다.\n",
    "- Topic_proportions & assignments 가 핵심 프로세스이다.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# document bundles\n",
    "documents = [[\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num of topic\n",
    "K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 각 토픽이 각 문서에 할당되는 횟수\n",
    "# 카운터로 구성된 리스트\n",
    "# 각 카운터는 각 문서를 의미한다.\n",
    "document_topic_counts = [Counter() for _ in documents] # [Counter() , Counter() ,..]\n",
    "\n",
    "# 각 단어가 각 토픽에 할당되는 횟수\n",
    "# 카운터로 구성된 리스트\n",
    "# 각 카운터는 각 토픽을 의미\n",
    "topic_word_counts = [Counter() for _ in range(K)] # [Counter() , Counter() ,..]\n",
    "\n",
    "# 각 토픽에 할당되는 총 단어 수\n",
    "# 숫자로 구성된 리스트\n",
    "# 각각의 숫자는 각 토픽을 의미한다.\n",
    "topic_counts = [0 for _ in range(K)] # [0,0,0,...]\n",
    "\n",
    "document_lengths = [len(doc) for doc in documents] #[len(doc) , len(doc) , len(doc),...]\n",
    "\n",
    "distinct_words = set(word for document in documents for word in document) # set(words in document)\n",
    "\n",
    "V = len(distinct_words) # len(set(words in document))\n",
    "\n",
    "D = len(documents) # len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_topic_given_document(topic,d,alpha=0.1):\n",
    "    # 문서 d의 모든 단어 가운데 topic에 속하는\n",
    "    # 단어의 비율(alpha를 더해 스무딩)\n",
    "    return ((document_topic_counts[d][topic] + alpha)/\n",
    "           (document_lengths[d] + K*alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_word_given_topic(word , topic , beta = 0.1):\n",
    "    # topic 에 속한 단어 가운데 word의 비율\n",
    "    # beta를 더해 스무딩\n",
    "    return ((topic_word_counts[topic][word] + beta) /\n",
    "           (topic_counts[topic] + V * beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic_weight(d, word , k):\n",
    "    # 문서와 문서의 단어가 주어지면\n",
    "    # k 번째 토픽의 가중치를 반환\n",
    "    return p_word_given_topic(word,k) * p_topic_given_document(k,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def sample_from(weights):\n",
    "    # i를 weights[i] / sum(weights)\n",
    "    # 확률로 반환\n",
    "    total = sum(weights)\n",
    "    # 0과 total 사이를 균일하게 선택\n",
    "    rnd = total * random.random()\n",
    "    # 아래 식을 만족하는 가장 작은 i를 반환\n",
    "    # weights[0] + ... + weights[i] >= rnd\n",
    "    for i, w in enumerate(weights):\n",
    "        rnd -= w\n",
    "        if rnd <= 0:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_new_topic(d, word):\n",
    "    return sample_from([topic_weight(d, word, k) for k in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "# topic 수 지정\n",
    "K=4\n",
    "\n",
    "# 각 단어를 임의의 토픽에 랜덤 배정\n",
    "document_topics = [[random.randrange(K) for word in document]\n",
    "                    for document in documents]\n",
    "\n",
    "# 위와 같이 랜덤 초기화한 상태에서 \n",
    "# AB를 구하는 데 필요한 숫자를 세어봄\n",
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1\n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1\n",
    "        document_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({0: 1, 2: 2, 3: 4}),\n",
       " Counter({1: 2, 2: 2, 3: 1}),\n",
       " Counter({0: 2, 1: 2, 2: 2}),\n",
       " Counter({0: 2, 2: 2, 3: 1}),\n",
       " Counter({1: 1, 2: 1, 3: 2}),\n",
       " Counter({0: 3, 2: 1, 3: 2}),\n",
       " Counter({0: 1, 1: 1, 2: 1, 3: 1}),\n",
       " Counter({0: 1, 1: 2, 2: 1}),\n",
       " Counter({0: 1, 1: 2, 3: 1}),\n",
       " Counter({0: 2, 2: 1, 3: 1}),\n",
       " Counter({0: 1, 2: 2}),\n",
       " Counter({1: 1, 2: 2, 3: 1}),\n",
       " Counter({0: 1, 2: 1, 3: 1}),\n",
       " Counter({1: 4, 2: 1}),\n",
       " Counter({0: 1, 2: 1, 3: 1})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'Big Data': 1,\n",
       "          'C++': 1,\n",
       "          'HBase': 1,\n",
       "          'Hadoop': 1,\n",
       "          'Haskell': 1,\n",
       "          'Java': 1,\n",
       "          'R': 1,\n",
       "          'artificial intelligence': 1,\n",
       "          'libsvm': 1,\n",
       "          'pandas': 2,\n",
       "          'regression': 1,\n",
       "          'scikit-learn': 2,\n",
       "          'statistics': 1,\n",
       "          'statsmodels': 1}),\n",
       " Counter({'Cassandra': 1,\n",
       "          'HBase': 1,\n",
       "          'Mahout': 1,\n",
       "          'MongoDB': 1,\n",
       "          'MySQL': 1,\n",
       "          'Postgres': 1,\n",
       "          'Python': 1,\n",
       "          'databases': 1,\n",
       "          'decision trees': 1,\n",
       "          'deep learning': 2,\n",
       "          'neural networks': 2,\n",
       "          'numpy': 1,\n",
       "          'theory': 1}),\n",
       " Counter({'C++': 1,\n",
       "          'Cassandra': 1,\n",
       "          'HBase': 1,\n",
       "          'Java': 2,\n",
       "          'MongoDB': 1,\n",
       "          'Postgres': 1,\n",
       "          'Python': 2,\n",
       "          'R': 2,\n",
       "          'artificial intelligence': 1,\n",
       "          'machine learning': 1,\n",
       "          'mathematics': 1,\n",
       "          'probability': 1,\n",
       "          'regression': 2,\n",
       "          'scipy': 1,\n",
       "          'statistics': 1,\n",
       "          'statsmodels': 1}),\n",
       " Counter({'Big Data': 2,\n",
       "          'Hadoop': 1,\n",
       "          'MapReduce': 1,\n",
       "          'NoSQL': 1,\n",
       "          'Python': 1,\n",
       "          'R': 1,\n",
       "          'Spark': 1,\n",
       "          'Storm': 1,\n",
       "          'libsvm': 1,\n",
       "          'machine learning': 1,\n",
       "          'probability': 2,\n",
       "          'programming languages': 1,\n",
       "          'statistics': 1,\n",
       "          'support vector machines': 1})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 15, 20, 16]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for iter in range(1000):\n",
    "    for d in range(D):\n",
    "        for i, (word, topic) in enumerate(zip(documents[d],document_topics[d])):\n",
    "            # 깁스 샘플링 수행을 위해\n",
    "            # 샘플링 대상 word와 topic을 제외하고 세어봄\n",
    "            document_topic_counts[d][topic] -= 1\n",
    "            topic_word_counts[topic][word] -= 1\n",
    "            topic_counts[topic] -= 1\n",
    "            document_lengths[d] -= 1\n",
    "\n",
    "            # 깁스 샘플링 대상 word와 topic을 제외한 \n",
    "            # 말뭉치 모든 word의 topic 정보를 토대로\n",
    "            # 샘플링 대상 word의 새로운 topic을 선택\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "\n",
    "            # 샘플링 대상 word의 새로운 topic을 반영해 \n",
    "            # 말뭉치 정보 업데이트\n",
    "            document_topic_counts[d][new_topic] += 1\n",
    "            topic_word_counts[new_topic][word] += 1\n",
    "            topic_counts[new_topic] += 1\n",
    "            document_lengths[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 7, 1: 0, 2: 0, 3: 0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topic_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Big Data': 3,\n",
       "         'C++': 1,\n",
       "         'Cassandra': 1,\n",
       "         'HBase': 1,\n",
       "         'Hadoop': 2,\n",
       "         'Haskell': 0,\n",
       "         'Java': 3,\n",
       "         'Mahout': 0,\n",
       "         'MapReduce': 1,\n",
       "         'MongoDB': 0,\n",
       "         'MySQL': 0,\n",
       "         'NoSQL': 0,\n",
       "         'Postgres': 0,\n",
       "         'Python': 0,\n",
       "         'R': 0,\n",
       "         'Spark': 1,\n",
       "         'Storm': 1,\n",
       "         'artificial intelligence': 0,\n",
       "         'databases': 0,\n",
       "         'decision trees': 0,\n",
       "         'deep learning': 1,\n",
       "         'libsvm': 0,\n",
       "         'machine learning': 0,\n",
       "         'mathematics': 0,\n",
       "         'neural networks': 0,\n",
       "         'numpy': 0,\n",
       "         'pandas': 0,\n",
       "         'probability': 0,\n",
       "         'programming languages': 1,\n",
       "         'regression': 0,\n",
       "         'scikit-learn': 0,\n",
       "         'scipy': 0,\n",
       "         'statistics': 0,\n",
       "         'statsmodels': 0,\n",
       "         'support vector machines': 0,\n",
       "         'theory': 0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_counts[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
